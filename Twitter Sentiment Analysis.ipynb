{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\12\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\12\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\12\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import pymorphy2\n",
    "from operator import itemgetter\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>class</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Microsoft All d more reasons why @Microsoft i...</td>\n",
       "      <td>reason better place work</td>\n",
       "      <td>neu</td>\n",
       "      <td>0.508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Microsoft @NCCEducation Great idea</td>\n",
       "      <td>great idea</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Microsoft Wow! That's nice!</td>\n",
       "      <td>wow nice</td>\n",
       "      <td>pos</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Microsoft Microsoft - If not already any chan...</td>\n",
       "      <td>microsoft already chance could make office ava...</td>\n",
       "      <td>neu</td>\n",
       "      <td>0.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@Microsoft üëè people over profit</td>\n",
       "      <td>people profit</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@Microsoft Guilt trip</td>\n",
       "      <td>guilt trip</td>\n",
       "      <td>neg</td>\n",
       "      <td>0.677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@Microsoft Well Done to you Microsoft for this...</td>\n",
       "      <td>well done microsoft initiative please life ret...</td>\n",
       "      <td>neu</td>\n",
       "      <td>0.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@Microsoft In this really hard situation you s...</td>\n",
       "      <td>really hard situation make office program free...</td>\n",
       "      <td>neu</td>\n",
       "      <td>0.546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>@Microsoft Something seriously wrong with @Mic...</td>\n",
       "      <td>something seriously wrong tier two support thr...</td>\n",
       "      <td>neu</td>\n",
       "      <td>0.483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>@Microsoft Then why aren't vendors who are qua...</td>\n",
       "      <td>vendor quarantined sick getting paid seems sil...</td>\n",
       "      <td>neu</td>\n",
       "      <td>0.577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>@Microsoft https://t.co/DoFp7Tx0cR aca.potocnj...</td>\n",
       "      <td>aca potocnjak</td>\n",
       "      <td>neu</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>@Microsoft HOW BOUT YOU EXTEND THE DEADLINES O...</td>\n",
       "      <td>bout extend deadline mcsa mcse retirement peop...</td>\n",
       "      <td>neu</td>\n",
       "      <td>0.841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>@Microsoft @Microsoft Why during a pandemic wo...</td>\n",
       "      <td>pandemic would raise system price seattle one ha</td>\n",
       "      <td>neu</td>\n",
       "      <td>0.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>@Microsoft Good job, shell out money for exclu...</td>\n",
       "      <td>good job shell money exclusivity mark site mal...</td>\n",
       "      <td>neu</td>\n",
       "      <td>0.565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>@Microsoft @Microsoft you are AWESOME! üôå</td>\n",
       "      <td>awesome</td>\n",
       "      <td>pos</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "0   @Microsoft All d more reasons why @Microsoft i...   \n",
       "1                 @Microsoft @NCCEducation Great idea   \n",
       "3                        @Microsoft Wow! That's nice!   \n",
       "4   @Microsoft Microsoft - If not already any chan...   \n",
       "6                     @Microsoft üëè people over profit   \n",
       "7                               @Microsoft Guilt trip   \n",
       "8   @Microsoft Well Done to you Microsoft for this...   \n",
       "9   @Microsoft In this really hard situation you s...   \n",
       "10  @Microsoft Something seriously wrong with @Mic...   \n",
       "11  @Microsoft Then why aren't vendors who are qua...   \n",
       "12  @Microsoft https://t.co/DoFp7Tx0cR aca.potocnj...   \n",
       "13  @Microsoft HOW BOUT YOU EXTEND THE DEADLINES O...   \n",
       "14  @Microsoft @Microsoft Why during a pandemic wo...   \n",
       "15  @Microsoft Good job, shell out money for exclu...   \n",
       "16           @Microsoft @Microsoft you are AWESOME! üôå   \n",
       "\n",
       "                                         preprocessed class  score  \n",
       "0                            reason better place work   neu  0.508  \n",
       "1                                          great idea   pos  0.804  \n",
       "3                                            wow nice   pos  1.000  \n",
       "4   microsoft already chance could make office ava...   neu  0.833  \n",
       "6                                       people profit   pos  0.744  \n",
       "7                                          guilt trip   neg  0.677  \n",
       "8   well done microsoft initiative please life ret...   neu  0.440  \n",
       "9   really hard situation make office program free...   neu  0.546  \n",
       "10  something seriously wrong tier two support thr...   neu  0.483  \n",
       "11  vendor quarantined sick getting paid seems sil...   neu  0.577  \n",
       "12                                      aca potocnjak   neu  1.000  \n",
       "13  bout extend deadline mcsa mcse retirement peop...   neu  0.841  \n",
       "14   pandemic would raise system price seattle one ha   neu  0.745  \n",
       "15  good job shell money exclusivity mark site mal...   neu  0.565  \n",
       "16                                            awesome   pos  1.000  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get: series of text to preprocess\n",
    "# return series of preprocessed text\n",
    "def preprocess(s):\n",
    "    vader = SentimentIntensityAnalyzer()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    ret = pd.Series(index=s.index)\n",
    "    for i in s.index:\n",
    "        reply = s[i]\n",
    "        # remove account including\n",
    "        reply = re.sub(r'@[\\w]+', ' ', reply)\n",
    "        # remove links\n",
    "        reply = re.sub(r'https?:[\\w./]*', ' ', reply)\n",
    "        reply = reply.lower()\n",
    "        # remove all non-words\n",
    "        reply = re.sub(r'[^a-z]', ' ', reply)        \n",
    "        # lemmatization\n",
    "        prepared = [lemmatizer.lemmatize(word) for word in reply.split()\n",
    "                    if lemmatizer.lemmatize(word) not in stop_words]\n",
    "        ret[i] = ' '.join(prepared)\n",
    "    return ret\n",
    "\n",
    "\n",
    "#get: dataframe of preprocessed text\n",
    "#return dataframe with two new columns: class and score\n",
    "def getClass(df):\n",
    "    #ret = pd.Series(index=s.index)\n",
    "    for i in df.index:\n",
    "        text = df['preprocessed'][i]\n",
    "        res = vader.polarity_scores(text)\n",
    "        # there is useless in our problem\n",
    "        del res['compound']\n",
    "        # get key (pos, neu or neg) with max value\n",
    "        df.loc[i, 'class'] = max(res.items(), key=itemgetter(1))[0]\n",
    "        df.loc[i, 'score'] = max(res.values())\n",
    "    return df\n",
    "        \n",
    "df = pd.read_excel('data.xlsx')\n",
    "df = df.drop(df.columns[0:8], axis=1)\n",
    "df['preprocessed'] = preprocess(df['text'])\n",
    "df = getClass(df)\n",
    "df.to_excel('result.xlsx')\n",
    "df[df['score'] != 0].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –û–ø–∏—Å–∞–Ω–∏–µ –∏ –¥—Ä—É–≥–∏–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏\n",
    "–î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤ —è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª VADER, —Ç.–∫. —ç—Ç–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –∑–∞—Ç–æ—á–µ–Ω–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–æ–≤ –∏–∑ —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–µ—Ç–µ–π. –ö–∞–∫–∏–µ –µ—â—ë –µ—Å—Ç—å –≤–∞—Ä–∏–∞–Ω—Ç—ã?\n",
    "* TextBlob. –ü–æ–∂–∞–ª—É–π, —Å–∞–º–∞—è –ø—Ä–æ—Å—Ç–∞—è –≤–µ—â—å, –≤—Å—Ç—Ä–æ–µ–Ω–∞ –≤ nltk. –ù–æ –ø–æ –∫–∞—á–µ—Å—Ç–≤—É —á—É—Ç—å —Ö—É–∂–µ VADER'–∞\n",
    "* FastText - –æ—Ç–ª–∏—á–Ω–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ word2vec. –û–¥–Ω–∞–∫–æ —Ç—Ä–µ–±—É–µ—Ç –æ–±—É—á–µ–Ω–∏—è, —Ç.–µ. —Ä—É—á–Ω–æ–π –ø–æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –º–µ—Ç–æ–∫ –Ω–∞ —Ç–µ–∫—Å—Ç–∞—Ö. –í —Å–∏–ª—É –º–∞–ª–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –≤—Ä–µ–º–µ–Ω–∏ –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç.\n",
    "–ï—Å–ª–∏ –±—ã –≤—Ä–µ–º–µ–Ω–∏ –±—ã–ª–æ –±–æ–ª—å—à–µ, —è –±—ã –ø–æ–ø—Ä–æ–±–æ–≤–∞–ª –æ–±—É—á–∏—Ç—å —Å–µ—Ç–æ—á–∫—É –Ω–∞ —É–∂–µ –º–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ—Ç–∫—Ä—ã—Ç—ã—Ö –Ω–∞–±–æ—Ä–∞—Ö —Ç–µ–∫—Å—Ç–æ–≤.\n",
    "# Workflow\n",
    "–í –ø—Ä–∏–Ω—Ü–∏–ø–µ, –æ–Ω –≤–∏–¥–µ–Ω –ø–æ —Ñ—É–Ω–∫—Ü–∏—è–º –≤—ã—à–µ. –ö–æ—Ä–æ—Ç–∫–æ –ø–µ—Ä–µ—á–∏—Å–ª–∏–º –æ—Å–Ω–æ–≤–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã:\n",
    "* –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö. –ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, API –¢–≤–∏—Ç—Ç–µ—Ä–∞ –¥–æ—Å—Ç—É–ø–Ω–æ —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è. –Ø –æ—Å—Ç–∞–≤–∏–ª –∑–∞—è–≤–∫—É, –Ω–æ –æ–Ω–∏ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—é—Ç—Å—è –≤ —Ä—É—á–Ω–æ–º —Ä–µ–∂–∏–º–µ –≤ —Ç–µ—á–µ–Ω–∏–µ 2-3 –¥–Ω–µ–π. –ü–æ—ç—Ç–æ–º—É —è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª —Å—Ç–æ—Ä–æ–Ω–Ω–∏–µ —Ä–µ—à–µ–Ω–∏—è –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ —Ç–≤–∏—Ç—ã, –æ–¥–Ω–∞–∫–æ —ç—Ç–∏ —Ä–µ—à–µ–Ω–∏—è –∏–º–µ—é—Ç —Å–∏–ª—å–Ω—ã–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è. –í –ø—Ä–∏–Ω—Ü–∏–ø–µ, —Ç.–∫. —è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª –≥–æ—Ç–æ–≤—É—é –º–æ–¥–µ–ª—å, –∞ –Ω–µ –æ–±—É—á–∞–ª —á—Ç–æ-—Ç–æ, –±–æ–ª—å—à–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö –∏ –Ω–µ –Ω—É–∂–Ω–æ.\n",
    "* –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞. –£–¥–∞–ª–µ–Ω–∏–µ –Ω–∏–∫–æ–≤, —Å—Å—ã–ª–æ–∫, –ø–µ—Ä–µ–≤–æ–¥ –≤ –Ω–∏–∂–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä\n",
    "* –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è. –° –∞–Ω–≥–ª–∏–π—Å–∫–∏–º —è–∑—ã–∫–æ–º —ç—Ç–æ –Ω–µ—Å–ª–æ–∂–Ω–æ\n",
    "* –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤: –æ–Ω–∏ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã –ø–æ —Å–º—ã—Å–ª—É, –Ω–æ –¥–æ–±–∞–≤–ª—é—è—Ç —à—É–º–∞.\n",
    "* –ü–æ–ª—É—á–µ–Ω–∏—è –∫–ª–∞—Å—Å–∞\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
